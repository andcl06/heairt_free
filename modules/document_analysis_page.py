# modules/document_analysis_page.py

import streamlit as st
import os # í™˜ê²½ ë³€ìˆ˜ ì ‘ê·¼ì„ ìœ„í•´ í•„ìš”
from loguru import logger # ë¡œê¹…ì„ ìœ„í•´ í•„ìš”
from datetime import datetime # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìœ„í•´ ì¶”ê°€

# --- ëª¨ë“ˆ ì„í¬íŠ¸ ---
from modules import ai_service # AI ì„œë¹„ìŠ¤ ëª¨ë“ˆ
from modules import document_processor # ìƒˆë¡œ ë§Œë“  ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“ˆ
from modules import database_manager # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ëª¨ë“ˆ ì„í¬íŠ¸

from langchain.memory import StreamlitChatMessageHistory # Langchain Streamlit í†µí•©


def document_analysis_page():
    """
    ë¬¸ì„œ ê¸°ë°˜ QA ì±—ë´‡ ë° íŠ¹ì•½ ìƒì„± ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤.
    """
    st.title("ğŸ“„ _Private Data :red[QA Chat]_")


# --- ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼, ìë™í™”, ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ê¸° ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜ ---
    col_home_button, col_trend_button, col_automaion_button = st.columns([0.2, 0.2, 0.6])
    with col_home_button:
        if st.button("ğŸ  ë©”ì¸í™”ë©´"):
            st.session_state.page = "landing"
            st.rerun()
    
    with col_trend_button:
        if st.button("ğŸ“ˆ ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ê¸°"):
            st.session_state.page = "trend"
            st.rerun()

    with col_automaion_button:
        if st.button("â° ìë™í™”"):
            st.session_state.page = "automation"
            st.rerun()

    st.markdown("---")

    # Gemini API í‚¤ ë¡œë“œ
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        st.error("ğŸš¨ ì˜¤ë¥˜: Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return # API í‚¤ ì—†ìœ¼ë©´ í˜ì´ì§€ ê¸°ëŠ¥ ë¹„í™œì„±í™”

    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì´ í˜ì´ì§€ì—ì„œ DB ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ì „ì— í™•ì‹¤íˆ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ë„ë¡ ë³´ì¥)
    database_manager.init_db()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "vectordb" not in st.session_state:
        st.session_state.vectordb = None
    if 'messages' not in st.session_state:
        st.session_state.messages = [{
            "role": "assistant",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”."
        }]
    # ì˜¤ë¥˜ ìˆ˜ì •: 'not not'ì„ 'not in'ìœ¼ë¡œ ë³€ê²½
    if "docs" not in st.session_state: # íŠ¹ì•½ ìƒì„± ê¸°ëŠ¥ì—ì„œ í•„ìš”
        st.session_state.docs = []
    # 'generated_endorsement_text' ëŒ€ì‹  'generated_endorsement_sections'ë¡œ ë³€ê²½í•˜ì—¬ ê° ì„¹ì…˜ë³„ë¡œ ì €ì¥
    if 'generated_endorsement_sections' not in st.session_state:
        st.session_state.generated_endorsement_sections = {}
    # ìƒˆë¡œ ì¶”ê°€: ìƒì„±ëœ íŠ¹ì•½ì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ (ì´ì œ ë°ì´í„°ë² ì´ìŠ¤ì™€ ë™ê¸°í™”)
    if 'generated_endorsement_full_text' not in st.session_state:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œë„ (í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ì˜¤ë¥˜ ì²˜ë¦¬)
        try:
            st.session_state['generated_endorsement_full_text'] = database_manager.get_latest_generated_endorsement() or ""
        except Exception as e:
            st.error(f"ğŸš¨ íŠ¹ì•½ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.session_state['generated_endorsement_full_text'] = "" # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”


    with st.sidebar:
        selected_menu = st.selectbox("ğŸ“Œ ë©”ë‰´ ì„ íƒ", ["ìµœì‹  QA", "íŠ¹ì•½ ìƒì„±"])
        uploaded_files = st.file_uploader("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ", type=['pdf', 'docx', 'pptx', 'txt'], accept_multiple_files=True)
        process = st.button("ğŸ“š ë¬¸ì„œ ì²˜ë¦¬")

    if process:
        if not uploaded_files:
            st.warning("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()

        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            docs = document_processor.get_text(uploaded_files)
            chunks = document_processor.get_text_chunks(docs)
            vectordb = document_processor.get_vectorstore(chunks)
            st.session_state.vectordb = vectordb
            st.session_state.docs = docs # 'docs' ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (íŠ¹ì•½ ìƒì„±ì—ì„œ ì‚¬ìš©)
            
            # ë¬¸ì„œì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„)
            all_text_from_docs = "\n\n".join([doc.page_content for doc in docs])
            database_manager.save_document_text(all_text_from_docs)

            st.success("âœ… ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ! ë©”ë‰´ë¥¼ ì„ íƒí•´ ì§„í–‰í•˜ì„¸ìš”.")
            st.session_state.messages = [{ # ë¬¸ì„œ ì²˜ë¦¬ í›„ ë©”ì‹œì§€ ì´ˆê¸°í™”
                "role": "assistant",
                "content": "ë¬¸ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì§ˆë¬¸í•˜ê±°ë‚˜ íŠ¹ì•½ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }]
            st.session_state.generated_endorsement_sections = {} # ë¬¸ì„œ ì²˜ë¦¬ ì‹œ íŠ¹ì•½ ì´ˆê¸°í™”
            st.session_state['generated_endorsement_full_text'] = "" # íŠ¹ì•½ ì „ì²´ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
            database_manager.save_generated_endorsement("") # DBì—ì„œë„ íŠ¹ì•½ ì´ˆê¸°í™” (ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„)
            st.rerun()


    if selected_menu == "ìµœì‹  QA":
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        history = StreamlitChatMessageHistory(key="chat_messages") # StreamlitChatMessageHistory ì´ˆê¸°í™”

        if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
            st.session_state.messages.append({"role": "user", "content": query})

            with st.chat_message("user"):
                st.markdown(query)

            with st.chat_message("assistant"):
                if not st.session_state.vectordb:
                    st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.")
                    st.stop()

                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    retriever = st.session_state.vectordb.as_retriever(search_type="similarity", k=3)
                    docs = retriever.get_relevant_documents(query)

                    context = "\n\n".join([doc.page_content for doc in docs])
                    final_prompt = f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ë¬¸ì„œ ë‚´ìš©]:
{context}

[ì§ˆë¬¸]:
{query}

[ë‹µë³€]:
"""
                    # ai_service ëª¨ë“ˆì˜ retry_ai_call í•¨ìˆ˜ ì‚¬ìš©
                    response_dict = ai_service.retry_ai_call(final_prompt, GEMINI_API_KEY)
                    answer = ai_service.clean_ai_response_text(response_dict.get("text", response_dict.get("error", "AI ì‘ë‹µ ì‹¤íŒ¨.")))

                    st.markdown(answer)
                    with st.expander("ğŸ“„ ì°¸ê³  ë¬¸ì„œ"):
                        for doc_ref in docs:
                            st.markdown(f"**ì¶œì²˜**: {doc_ref.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                            st.markdown(doc_ref.page_content)

                    st.session_state.messages.append({"role": "assistant", "content": answer})

    elif selected_menu == "íŠ¹ì•½ ìƒì„±":
        st.subheader("ğŸ“‘ ë³´í—˜ íŠ¹ì•½ ìƒì„±ê¸°")

        # ê¸°ì¡´ ë¡œì§ ìœ ì§€: ì„¸ì…˜ ìƒíƒœì— docsê°€ ì—†ìœ¼ë©´ ê²½ê³  (ë¬¸ì„œ ì²˜ë¦¬ í•„ìš”)
        if "docs" not in st.session_state or not st.session_state.docs:
            # í•˜ì§€ë§Œ ì´ì œ DBì—ì„œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ íŠ¹ì•½ ìƒì„±ì„ ì‹œë„í•  ìˆ˜ ìˆìŒ
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ê¸°ì¡´ ë™ì‘ì„ ìœ ì§€í•˜ê³ , DB ë¡œì§ì€ ìë™í™” í˜ì´ì§€ì—ì„œ í™œìš©
            st.warning("ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            st.stop()

        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ docsë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, DBì—ì„œ ë¶ˆëŸ¬ì˜¨ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©
        # í˜„ì¬ í˜ì´ì§€ì—ì„œëŠ” 'docs' ì„¸ì…˜ ìƒíƒœê°€ ìš°ì„ ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        all_text = "\n\n".join([doc.page_content for doc in st.session_state.docs])
        
        # íŠ¹ì•½ êµ¬ì„± í•­ëª© ì •ì˜ (í˜‘ì—…ì íŒŒì¼ì—ì„œ ê°€ì ¸ì˜´)
        sections = {
            "1. íŠ¹ì•½ì˜ ëª…ì¹­": "ìë™ì°¨ ë³´í—˜ í‘œì¤€ì•½ê´€ì„ ì°¸ê³ í•˜ì—¬ íŠ¹ì•½ì˜ **ëª…ì¹­**ì„ ì‘ì„±í•´ì¤˜.",
            "2. íŠ¹ì•½ì˜ ëª©ì ": "ì´ íŠ¹ì•½ì˜ **ëª©ì **ì„ ì„¤ëª…í•´ì¤˜.",
            "3. ë³´ì¥ ë²”ìœ„": "**ë³´ì¥ ë²”ìœ„**ì— ëŒ€í•´ ìƒì„¸íˆ ì‘ì„±í•´ì¤˜.",
            "4. ë³´í—˜ê¸ˆ ì§€ê¸‰ ì¡°ê±´": "**ë³´í—˜ê¸ˆ ì§€ê¸‰ ì¡°ê±´**ì„ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì¤˜.",
            "5. ë³´í—˜ë£Œ ì‚°ì • ë°©ì‹": "**ë³´í—˜ë£Œ ì‚°ì • ë°©ì‹**ì„ ì„¤ëª…í•´ì¤˜.",
            "6. ë©´ì±… ì‚¬í•­": "**ë©´ì±… ì‚¬í•­**ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì„ ì‘ì„±í•´ì¤˜.",
            "7. íŠ¹ì•½ì˜ ì ìš© ê¸°ê°„": "**ì ìš© ê¸°ê°„**ì„ ëª…ì‹œí•´ì¤˜.",
            "8. ê¸°íƒ€ íŠ¹ë³„ ì¡°ê±´": "**ê¸°íƒ€ íŠ¹ë³„ ì¡°ê±´**ì´ ìˆë‹¤ë©´ ì œì•ˆí•´ì¤˜.",
            # ìƒˆë¡œ ì¶”ê°€ëœ í•­ëª©ë“¤
            "9. ìš´ì „ê°€ëŠ¥ì ì œí•œ": "**ìš´ì „ì ì—°ë ¹ê³¼ ë²”ìœ„**ì— ë”°ë¥¸ íŠ¹ë³„ ì•½ê´€ì„ ì œì•ˆí•´ì¤˜.",
            "10. ë³´í—˜ë£Œ í• ì¸": "**ë³´í—˜ë£Œ í• ì¸**ì— í•´ë‹¹í•˜ëŠ” íŠ¹ë³„ ì•½ê´€ì„ ì‘ì„±í•´ì¤˜.",
            "11. ë³´ì¥ í™•ëŒ€": "**ë²•ë¥ ë¹„ìš© ë° ë‹¤ë¥¸ ìë™ì°¨ ìš´ì „**ì— í•´ë‹¹í•˜ëŠ” íŠ¹ë³„ ì•½ê´€ì„ ì‘ì„±í•´ì¤˜"
        }

        if st.button("ğŸš€ íŠ¹ì•½ ìƒì„± ì‹œì‘"):
            all_generated_sections = {} # ê° ì„¹ì…˜ë³„ ë‹µë³€ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            full_text_for_download = "" # ë‹¤ìš´ë¡œë“œìš© ì „ì²´ í…ìŠ¤íŠ¸ (ì´ì œ ì„¸ì…˜ ìƒíƒœì—ë„ ì €ì¥)

            with st.spinner("Gemini APIì— ìˆœì°¨ì ìœ¼ë¡œ ìš”ì²­ ì¤‘ì…ë‹ˆë‹¤..."):
                for title, question in sections.items():
                    st.info(f"â³ {title} ìƒì„± ì¤‘...")
                    prompt = f"""
ë„ˆëŠ” ìë™ì°¨ ë³´í—˜ì„ ì„¤ê³„í•˜ê³  ìˆëŠ” ë³´í—˜ì‚¬ ì§ì›ì´ì•¼.
ë‹¤ìŒ ì¡°ê±´ì— ë”°ë¼ ìë™ì°¨ ë³´í—˜ íŠ¹ì•½ì˜ '{title}'ì„ 3~5ì¤„ ì •ë„ë¡œ ì‘ì„±í•´ì¤˜.

[ê¸°íš ëª©ì ]
- ì´ íŠ¹ì•½ì€ ë³´í—˜ ìƒí’ˆ ê¸°íš ì´ˆê¸° ë‹¨ê³„ì—ì„œ íŠ¸ë Œë“œ ì¡°ì‚¬ ë° ë°©í–¥ì„± ë„ì¶œì— ë„ì›€ ë˜ëŠ” ëª©ì ìœ¼ë¡œ ì‘ì„±ë¼ì•¼ í•´.
- ìƒˆë¡œìš´ ê¸°ìˆ (ì˜ˆ: ë¸”ë™ë°•ìŠ¤, ììœ¨ì£¼í–‰ ë“±)ì´ë‚˜ ìµœê·¼ ì‚¬íšŒì  ì´ìŠˆ(ì˜ˆ: ê³ ë ¹ ìš´ì „ì ì¦ê°€ ë“±)ë¥¼ ë°˜ì˜í•´ë„ ì¢‹ì•„.
- í‘œì¤€ì•½ê´€ í‘œí˜„ ë°©ì‹ì„ ë”°ë¼ì¤˜.

[í‘œì¤€ì•½ê´€ ë‚´ìš©]
{all_text}

[ì§ˆë¬¸]
{question}

[ë‹µë³€]
"""
                    # ai_service ëª¨ë“ˆì˜ retry_ai_call í•¨ìˆ˜ ì‚¬ìš©
                    response_dict = ai_service.retry_ai_call(prompt, GEMINI_API_KEY)
                    answer = ai_service.clean_ai_response_text(response_dict.get("text", response_dict.get("error", "AI ì‘ë‹µ ì‹¤íŒ¨.")))
                    
                    all_generated_sections[title] = answer # ê° ì„¹ì…˜ë³„ë¡œ ì €ì¥
                    full_text_for_download += f"#### {title}\n{answer.strip()}\n\n" # ë‹¤ìš´ë¡œë“œìš© í…ìŠ¤íŠ¸ì— ì¶”ê°€

            st.session_state.generated_endorsement_sections = all_generated_sections # ì„¸ì…˜ ìƒíƒœì— ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
            st.session_state['generated_endorsement_full_text'] = full_text_for_download # ìƒˆë¡œ ì¶”ê°€: ì „ì²´ íŠ¹ì•½ í…ìŠ¤íŠ¸ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            database_manager.save_generated_endorsement(full_text_for_download) # ë°ì´í„°ë² ì´ìŠ¤ì— íŠ¹ì•½ ì €ì¥
            st.success("âœ… íŠ¹ì•½ ìƒì„± ì™„ë£Œ!")
            st.rerun() # ìƒì„± ì™„ë£Œ í›„ UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ rerun

        # ìƒì„±ëœ íŠ¹ì•½ì´ ì„¸ì…˜ ìƒíƒœì— ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state.generated_endorsement_sections:
            st.markdown("### ğŸ“„ ìµœì¢… ìƒì„±ëœ íŠ¹ì•½")
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ê° ì„¹ì…˜ì„ ë°˜ë³µí•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œ
            full_text_for_download_display = "" # í™”ë©´ í‘œì‹œì™€ ë‹¤ìš´ë¡œë“œìš© í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬
            for title, content in st.session_state.generated_endorsement_sections.items():
                st.markdown(f"#### {title}") # í˜‘ì—…ì ì½”ë“œì²˜ëŸ¼ ê° ì„¹ì…˜ ì œëª©ì„ ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¡œ
                st.write(content) # ê° ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œí•˜ì—¬ ê¸€ì í¬ê¸° ì œì–´
                full_text_for_download_display += f"#### {title}\n{content.strip()}\n\n" # ë‹¤ìš´ë¡œë“œìš© ...

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
            st.download_button(
                label="ğŸ“¥ íŠ¹ì•½ ì „ì²´ ë‹¤ìš´ë¡œë“œ (.txt)",
                data=full_text_for_download_display, # í™”ë©´ì— í‘œì‹œëœ ë‚´ìš©ê³¼ ë™ì¼í•˜ê²Œ ë‹¤ìš´ë¡œë“œ
                file_name=f"ìƒì„±ëœ_ë³´í—˜_íŠ¹ì•½_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt", # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                mime="text/plain"
            )
